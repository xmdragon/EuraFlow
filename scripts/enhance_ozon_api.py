#!/usr/bin/env python3
"""
å¢žå¼ºç‰ˆOZON APIæ–‡æ¡£æ‹†åˆ†å™¨ - æå–è¯¦ç»†çš„APIä¿¡æ¯
"""
import os
import re
import json
from bs4 import BeautifulSoup, Comment
from pathlib import Path
import html2text
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# é…ç½®
SOURCE_FILE = "/home/grom/EuraFlow/docs/OzonSellerAPI.html"
OUTPUT_DIR = "/home/grom/EuraFlow/docs/ozon-api-detailed"

def clean_filename(name):
    """æ¸…ç†æ–‡ä»¶åï¼Œç§»é™¤ç‰¹æ®Šå­—ç¬¦"""
    name = name.replace('/', '_').replace('\\', '_')
    name = re.sub(r'[^\w\-_\.]', '', name)
    name = name.lstrip('_')
    return name

def extract_json_from_element(element):
    """ä»ŽHTMLå…ƒç´ ä¸­æå–JSONå†…å®¹"""
    if not element:
        return None

    # æŸ¥æ‰¾ä»£ç å—
    code_blocks = element.find_all(['code', 'pre'])
    for block in code_blocks:
        text = block.get_text().strip()
        if text.startswith('{') or text.startswith('['):
            try:
                # å°è¯•è§£æžJSON
                parsed = json.loads(text)
                return json.dumps(parsed, indent=2, ensure_ascii=False)
            except:
                # å¦‚æžœä¸æ˜¯æœ‰æ•ˆJSONï¼Œè¿”å›žåŽŸå§‹æ–‡æœ¬
                return text

    return None

def extract_api_details(soup, api_path):
    """ä»Žsoupä¸­æå–ç‰¹å®šAPIçš„è¯¦ç»†ä¿¡æ¯"""
    api_info = {
        'path': api_path,
        'method': 'POST',  # å¤§éƒ¨åˆ†OZON APIéƒ½æ˜¯POST
        'title': '',
        'description': '',
        'request_schema': None,
        'request_example': None,
        'response_schema': None,
        'response_example': None,
        'parameters': [],
        'responses': {},
        'errors': []
    }

    # æŸ¥æ‰¾åŒ…å«APIè·¯å¾„çš„å…ƒç´ 
    path_elements = soup.find_all(text=re.compile(re.escape(api_path)))
    if not path_elements:
        return api_info

    # æ‰¾åˆ°åŒ…å«æ­¤APIçš„ä¸»è¦å®¹å™¨
    main_container = None
    for elem in path_elements:
        if elem.parent:
            # æŸ¥æ‰¾æœ€è¿‘çš„å¤§å®¹å™¨
            container = elem.parent
            while container and container.name not in ['div', 'section', 'article']:
                container = container.parent

            if container:
                # æ£€æŸ¥å®¹å™¨æ˜¯å¦åŒ…å«APIç›¸å…³å†…å®¹
                container_text = container.get_text()
                if 'REQUEST BODY SCHEMA' in container_text or 'RESPONSE SCHEMA' in container_text:
                    main_container = container
                    break

    if not main_container:
        # å¦‚æžœæ‰¾ä¸åˆ°æ ‡å‡†å®¹å™¨ï¼Œæ‰©å¤§æœç´¢èŒƒå›´
        for elem in path_elements:
            if elem.parent:
                # æŸ¥æ‰¾åŒ…å«æ›´å¤šå†…å®¹çš„çˆ¶å…ƒç´ 
                container = elem.parent
                for _ in range(10):  # å‘ä¸ŠæŸ¥æ‰¾10å±‚
                    if container.parent:
                        container = container.parent
                        container_text = container.get_text()
                        if len(container_text) > 500 and ('schema' in container_text.lower() or 'response' in container_text.lower()):
                            main_container = container
                            break
                    else:
                        break
                if main_container:
                    break

    if not main_container:
        logger.warning(f"æœªæ‰¾åˆ°API {api_path} çš„è¯¦ç»†å®¹å™¨")
        return api_info

    # æå–æ ‡é¢˜
    title_elem = main_container.find(['h1', 'h2', 'h3', 'h4'])
    if title_elem:
        api_info['title'] = title_elem.get_text(strip=True)

    # æå–æè¿°
    # æŸ¥æ‰¾æè¿°æ®µè½
    desc_patterns = ['æè¿°', 'description', 'æ–¹æ³•', 'æŽ¥å£']
    for pattern in desc_patterns:
        desc_elem = main_container.find(text=re.compile(pattern, re.I))
        if desc_elem and desc_elem.parent:
            # èŽ·å–æè¿°æ–‡æœ¬
            next_elem = desc_elem.parent.find_next_sibling()
            if next_elem:
                desc_text = next_elem.get_text(strip=True)
                if desc_text and len(desc_text) > 10:
                    api_info['description'] = desc_text
                    break

    # æå–è¯·æ±‚Schema
    request_schema_text = main_container.find(text=re.compile('REQUEST BODY SCHEMA', re.I))
    if request_schema_text:
        schema_container = request_schema_text.parent
        while schema_container and not schema_container.find_all(['table', 'pre', 'code']):
            schema_container = schema_container.find_next_sibling()

        if schema_container:
            # æå–å‚æ•°è¡¨æ ¼
            table = schema_container.find('table')
            if table:
                api_info['parameters'] = extract_parameters_from_table(table)

            # æå–JSONç¤ºä¾‹
            json_example = extract_json_from_element(schema_container)
            if json_example:
                api_info['request_example'] = json_example

    # æå–å“åº”Schema
    response_schema_text = main_container.find(text=re.compile('RESPONSE SCHEMA', re.I))
    if response_schema_text:
        schema_container = response_schema_text.parent
        while schema_container and not schema_container.find_all(['table', 'pre', 'code']):
            schema_container = schema_container.find_next_sibling()

        if schema_container:
            # æå–å“åº”è¡¨æ ¼
            table = schema_container.find('table')
            if table:
                response_params = extract_parameters_from_table(table)
                api_info['responses']['200'] = {
                    'description': 'æˆåŠŸå“åº”',
                    'schema': response_params
                }

            # æå–JSONç¤ºä¾‹
            json_example = extract_json_from_element(schema_container)
            if json_example:
                api_info['response_example'] = json_example

    # æŸ¥æ‰¾æ‰€æœ‰JSONä»£ç å—
    code_blocks = main_container.find_all(['code', 'pre'])
    request_examples = []
    response_examples = []

    for block in code_blocks:
        text = block.get_text().strip()
        if text.startswith('{') or text.startswith('['):
            try:
                parsed = json.loads(text)
                formatted = json.dumps(parsed, indent=2, ensure_ascii=False)

                # åˆ¤æ–­æ˜¯è¯·æ±‚è¿˜æ˜¯å“åº”ç¤ºä¾‹
                if any(key in text.lower() for key in ['page', 'limit', 'filter', 'search']):
                    request_examples.append(formatted)
                else:
                    response_examples.append(formatted)
            except:
                continue

    if request_examples and not api_info['request_example']:
        api_info['request_example'] = request_examples[0]

    if response_examples and not api_info['response_example']:
        api_info['response_example'] = response_examples[0]

    return api_info

def extract_parameters_from_table(table):
    """ä»Žè¡¨æ ¼ä¸­æå–å‚æ•°ä¿¡æ¯"""
    parameters = []

    if not table:
        return parameters

    rows = table.find_all('tr')
    headers = []

    # æå–è¡¨å¤´
    if rows:
        header_row = rows[0]
        headers = [th.get_text(strip=True).lower() for th in header_row.find_all(['th', 'td'])]

    # æå–å‚æ•°è¡Œ
    for row in rows[1:]:
        cells = row.find_all(['td', 'th'])
        if len(cells) >= 2:
            param = {}

            for i, cell in enumerate(cells):
                cell_text = cell.get_text(strip=True)
                if i < len(headers):
                    header = headers[i]
                    if 'name' in header or header == 'å‚æ•°':
                        param['name'] = cell_text
                    elif 'type' in header or header == 'ç±»åž‹':
                        param['type'] = cell_text
                    elif 'required' in header or header == 'å¿…éœ€':
                        param['required'] = cell_text.lower() in ['true', 'yes', 'æ˜¯', 'required']
                    elif 'description' in header or header == 'æè¿°':
                        param['description'] = cell_text
                    elif 'default' in header or header == 'é»˜è®¤å€¼':
                        param['default'] = cell_text

            if param.get('name'):
                parameters.append(param)

    return parameters

def generate_detailed_markdown(api_info):
    """ç”Ÿæˆè¯¦ç»†çš„Markdownæ–‡æ¡£"""
    md_lines = []

    # æ ‡é¢˜
    title = api_info.get('title', api_info['path'])
    md_lines.append(f"# {title}")
    md_lines.append("")

    # APIåŸºæœ¬ä¿¡æ¯
    md_lines.append("## æŽ¥å£ä¿¡æ¯")
    md_lines.append("")
    md_lines.append("| å±žæ€§ | å€¼ |")
    md_lines.append("|------|-----|")
    md_lines.append(f"| **HTTPæ–¹æ³•** | `{api_info['method']}` |")
    md_lines.append(f"| **è¯·æ±‚è·¯å¾„** | `{api_info['path']}` |")
    md_lines.append(f"| **Content-Type** | `application/json` |")
    md_lines.append("")

    # æè¿°
    if api_info.get('description'):
        md_lines.append("## æŽ¥å£æè¿°")
        md_lines.append("")
        md_lines.append(api_info['description'])
        md_lines.append("")

    # è¯·æ±‚å‚æ•°
    if api_info.get('parameters'):
        md_lines.append("## è¯·æ±‚å‚æ•°")
        md_lines.append("")
        md_lines.append("| å‚æ•°å | ç±»åž‹ | å¿…éœ€ | é»˜è®¤å€¼ | æè¿° |")
        md_lines.append("|--------|------|------|--------|------|")

        for param in api_info['parameters']:
            name = param.get('name', '-')
            param_type = param.get('type', '-')
            required = 'æ˜¯' if param.get('required', False) else 'å¦'
            default = param.get('default', '-')
            description = param.get('description', '-')

            md_lines.append(f"| `{name}` | {param_type} | {required} | {default} | {description} |")

        md_lines.append("")

    # è¯·æ±‚ç¤ºä¾‹
    if api_info.get('request_example'):
        md_lines.append("## è¯·æ±‚ç¤ºä¾‹")
        md_lines.append("")
        md_lines.append("```json")
        md_lines.append(api_info['request_example'])
        md_lines.append("```")
        md_lines.append("")

    # å“åº”ç»“æž„
    if api_info.get('responses'):
        md_lines.append("## å“åº”ç»“æž„")
        md_lines.append("")

        for status_code, response in api_info['responses'].items():
            md_lines.append(f"### {status_code} - {response.get('description', 'æˆåŠŸ')}")
            md_lines.append("")

            if response.get('schema'):
                md_lines.append("| å­—æ®µå | ç±»åž‹ | æè¿° |")
                md_lines.append("|--------|------|------|")

                for field in response['schema']:
                    name = field.get('name', '-')
                    field_type = field.get('type', '-')
                    description = field.get('description', '-')
                    md_lines.append(f"| `{name}` | {field_type} | {description} |")

                md_lines.append("")

    # å“åº”ç¤ºä¾‹
    if api_info.get('response_example'):
        md_lines.append("## å“åº”ç¤ºä¾‹")
        md_lines.append("")
        md_lines.append("```json")
        md_lines.append(api_info['response_example'])
        md_lines.append("```")
        md_lines.append("")

    # é”™è¯¯ç 
    if api_info.get('errors'):
        md_lines.append("## é”™è¯¯ç ")
        md_lines.append("")
        md_lines.append("| é”™è¯¯ç  | è¯´æ˜Ž |")
        md_lines.append("|--------|------|")

        for error in api_info['errors']:
            code = error.get('code', '-')
            message = error.get('message', '-')
            md_lines.append(f"| {code} | {message} |")

        md_lines.append("")

    # é€šç”¨é”™è¯¯è¯´æ˜Ž
    md_lines.append("## é€šç”¨é”™è¯¯ç ")
    md_lines.append("")
    md_lines.append("| HTTPçŠ¶æ€ç  | é”™è¯¯ç  | è¯´æ˜Ž |")
    md_lines.append("|------------|--------|------|")
    md_lines.append("| 400 | BAD_REQUEST | è¯·æ±‚å‚æ•°é”™è¯¯ |")
    md_lines.append("| 401 | UNAUTHORIZED | æœªæŽˆæƒè®¿é—® |")
    md_lines.append("| 403 | FORBIDDEN | ç¦æ­¢è®¿é—® |")
    md_lines.append("| 404 | NOT_FOUND | èµ„æºä¸å­˜åœ¨ |")
    md_lines.append("| 429 | TOO_MANY_REQUESTS | è¯·æ±‚é¢‘çŽ‡é™åˆ¶ |")
    md_lines.append("| 500 | INTERNAL_ERROR | æœåŠ¡å™¨å†…éƒ¨é”™è¯¯ |")
    md_lines.append("")

    return "\n".join(md_lines)

def parse_api_list():
    """è§£æžçŽ°æœ‰çš„APIåˆ—è¡¨"""
    index_file = "/home/grom/EuraFlow/docs/ozon-api/index.md"
    if not os.path.exists(index_file):
        logger.error("ç´¢å¼•æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·å…ˆè¿è¡ŒåŸºç¡€æ‹†åˆ†è„šæœ¬")
        return []

    apis = []
    with open(index_file, 'r', encoding='utf-8') as f:
        content = f.read()

    # ä»Žç´¢å¼•æ–‡ä»¶ä¸­æå–APIè·¯å¾„
    lines = content.split('\n')
    for line in lines:
        if '| POST |' in line and '`/' in line:
            # æå–è·¯å¾„
            match = re.search(r'`(/[^`]+)`', line)
            if match:
                path = match.group(1)
                apis.append(path)

    return list(set(apis))  # åŽ»é‡

def main():
    """ä¸»å‡½æ•°"""
    logger.info("å¼€å§‹å¢žå¼ºOZON APIæ–‡æ¡£...")

    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    Path(OUTPUT_DIR).mkdir(parents=True, exist_ok=True)

    # è¯»å–HTMLæ–‡æ¡£
    logger.info(f"è¯»å–HTMLæ–‡æ¡£: {SOURCE_FILE}")
    with open(SOURCE_FILE, 'r', encoding='utf-8') as f:
        content = f.read()

    soup = BeautifulSoup(content, 'html.parser')

    # èŽ·å–APIåˆ—è¡¨
    api_paths = parse_api_list()
    if not api_paths:
        logger.error("æœªæ‰¾åˆ°APIåˆ—è¡¨")
        return

    logger.info(f"æ‰¾åˆ° {len(api_paths)} ä¸ªAPIéœ€è¦å¤„ç†")

    # å¤„ç†æ¯ä¸ªAPI
    processed = 0
    for api_path in api_paths:
        try:
            logger.info(f"å¤„ç†API: {api_path}")

            # æå–APIè¯¦ç»†ä¿¡æ¯
            api_info = extract_api_details(soup, api_path)

            # ç”ŸæˆMarkdownæ–‡æ¡£
            markdown_content = generate_detailed_markdown(api_info)

            # ä¿å­˜æ–‡ä»¶
            filename = clean_filename(api_path)
            if not filename:
                filename = f"api_{processed}"
            filename = f"post_{filename}.md"

            filepath = os.path.join(OUTPUT_DIR, filename)
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(markdown_content)

            processed += 1
            logger.info(f"  [{processed}/{len(api_paths)}] å·²ä¿å­˜: {filename}")

        except Exception as e:
            logger.error(f"å¤„ç†API {api_path} æ—¶å‡ºé”™: {e}")
            continue

    # åˆ›å»ºå¢žå¼ºç‰ˆç´¢å¼•
    create_enhanced_index(OUTPUT_DIR, processed)

    logger.info(f"å®Œæˆï¼å…±å¤„ç† {processed} ä¸ªAPI")

def create_enhanced_index(output_dir, count):
    """åˆ›å»ºå¢žå¼ºç‰ˆç´¢å¼•æ–‡ä»¶"""
    import datetime
    processed_time = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')

    index_path = os.path.join(output_dir, "README.md")

    content = "# OZON Seller API è¯¦ç»†æ–‡æ¡£\n\n"
    content += f"æœ¬ç›®å½•åŒ…å« {count} ä¸ª OZON Seller API çš„è¯¦ç»†æ–‡æ¡£ï¼Œæ¯ä¸ªAPIéƒ½åŒ…å«ï¼š\n\n"
    content += "- ðŸ“‹ æŽ¥å£åŸºæœ¬ä¿¡æ¯ï¼ˆè·¯å¾„ã€æ–¹æ³•ã€Content-Typeï¼‰\n"
    content += "- ðŸ“ è¯¦ç»†çš„æŽ¥å£æè¿°å’Œç”¨é€”è¯´æ˜Ž\n"
    content += "- ðŸ“¥ å®Œæ•´çš„è¯·æ±‚å‚æ•°è¡¨æ ¼ï¼ˆå‚æ•°åã€ç±»åž‹ã€å¿…éœ€æ€§ã€é»˜è®¤å€¼ã€æè¿°ï¼‰\n"
    content += "- ðŸ’¡ è¯·æ±‚æ•°æ®ç»“æž„å’ŒJSONç¤ºä¾‹\n"
    content += "- ðŸ“¤ å“åº”æ•°æ®ç»“æž„è¯´æ˜Ž\n"
    content += "- âœ… å“åº”JSONç¤ºä¾‹\n"
    content += "- âŒ é”™è¯¯ç è¯´æ˜Ž\n\n"
    content += "## ä½¿ç”¨æ–¹æ³•\n\n"
    content += "1. **æŒ‰APIè·¯å¾„æŸ¥æ‰¾**ï¼šæ–‡ä»¶åæ ¼å¼ä¸º `post_{api_path}.md`\n"
    content += "2. **ç¤ºä¾‹**ï¼š`POST /v3/product/list` å¯¹åº”æ–‡ä»¶ `post_v3_product_list.md`\n"
    content += "3. **æ‰€æœ‰æ–‡æ¡£éƒ½åŒ…å«å®Œæ•´çš„è¯·æ±‚/å“åº”æ ¼å¼å’Œç¤ºä¾‹**\n\n"
    content += "## æ–‡æ¡£ç‰¹ç‚¹\n\n"
    content += "- âœ… ä»Žå®˜æ–¹HTMLæ–‡æ¡£è‡ªåŠ¨æå–\n"
    content += "- âœ… åŒ…å«è¯¦ç»†çš„å‚æ•°ç±»åž‹å’Œç»“æž„\n"
    content += "- âœ… æä¾›JSONè¯·æ±‚/å“åº”ç¤ºä¾‹\n"
    content += "- âœ… æ”¯æŒä¸­æ–‡æè¿°\n"
    content += "- âœ… æ ¼å¼ç»Ÿä¸€ï¼Œä¾¿äºŽæŸ¥é˜…\n\n"
    content += f"## æ›´æ–°æ—¶é—´\n\n{processed_time}\n"

    with open(index_path, 'w', encoding='utf-8') as f:
        f.write(content)

if __name__ == "__main__":
    main()